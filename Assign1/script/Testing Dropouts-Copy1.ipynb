{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle \n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(trainset_new, batch_size=64, shuffle=True)\n",
    "# valid_loader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "trainset_imoprt = pickle.load(open(\"../data/kaggle/train_labeled.p\", \"rb\"))\n",
    "validset_import = pickle.load(open(\"../data/kaggle/validation.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset_imoprt, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validset_import, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 20)\n",
    "        self.linear2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self,x ):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.dropout(F.relu(self.linear1(x)), p = 0.3)\n",
    "        x = F.dropout(F.relu(self.linear2(x)), p = 0.7)\n",
    "        if self.count < 3:\n",
    "            print(x[0])\n",
    "        self.count += 1\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CPU only training\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    layer_1_weights = 0\n",
    "    layer_2_weights = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += F.nll_loss(output, target).data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    layer_1_weights = model.state_dict()['linear1.weight']\n",
    "    layer_2_weights = model.state_dict()['linear2.weight']\n",
    "        \n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    return train_loss, layer_1_weights, layer_2_weights\n",
    "def test(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    layer_1_weights = 0\n",
    "    layer_2_weights = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "    layer_1_weights = model.state_dict()['linear1.weight']\n",
    "    layer_2_weights = model.state_dict()['linear2.weight']\n",
    "\n",
    "    test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))\n",
    "    return test_loss, layer_1_weights, layer_2_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.2313\n",
      " 0.1274\n",
      " 0.0837\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 2.311021\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.0000\n",
      "  0.0000\n",
      "  8.0154\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Variable containing:\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.2429\n",
      " 0.0000\n",
      " 0.4288\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0488\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 2.316731\n",
      "Train Epoch: 1 [1280/3000 (43%)]\tLoss: 2.240244\n",
      "Train Epoch: 1 [1920/3000 (64%)]\tLoss: 2.152262\n",
      "Train Epoch: 1 [2560/3000 (85%)]\tLoss: 2.129595\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 2.005448\n",
      "Train Epoch: 2 [640/3000 (21%)]\tLoss: 2.084245\n",
      "Train Epoch: 2 [1280/3000 (43%)]\tLoss: 2.087893\n",
      "Train Epoch: 2 [1920/3000 (64%)]\tLoss: 1.862667\n",
      "Train Epoch: 2 [2560/3000 (85%)]\tLoss: 1.882148\n",
      "Train Epoch: 3 [0/3000 (0%)]\tLoss: 1.937448\n",
      "Train Epoch: 3 [640/3000 (21%)]\tLoss: 1.782587\n",
      "Train Epoch: 3 [1280/3000 (43%)]\tLoss: 1.832493\n",
      "Train Epoch: 3 [1920/3000 (64%)]\tLoss: 1.580616\n",
      "Train Epoch: 3 [2560/3000 (85%)]\tLoss: 1.707266\n",
      "Train Epoch: 4 [0/3000 (0%)]\tLoss: 1.679906\n",
      "Train Epoch: 4 [640/3000 (21%)]\tLoss: 1.645930\n",
      "Train Epoch: 4 [1280/3000 (43%)]\tLoss: 1.349282\n",
      "Train Epoch: 4 [1920/3000 (64%)]\tLoss: 1.673560\n",
      "Train Epoch: 4 [2560/3000 (85%)]\tLoss: 1.620597\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "train_layer_1 = []\n",
    "test_layer_1 = []\n",
    "train_layer_2 = []\n",
    "test_layer_2 = []\n",
    "model = SimpleNet()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "trlayer_1\n",
    "trlayer_2 \n",
    "for epoch in range(1, 5):\n",
    "    trainerror, trlayer_1, trlayer_2 = train(epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer number  0\n",
      "Size of the layer torch.Size([20, 784])\n",
      "Layer number  1\n",
      "Size of the layer torch.Size([20])\n",
      "Layer number  2\n",
      "Size of the layer torch.Size([10, 20])\n",
      "Layer number  3\n",
      "Size of the layer torch.Size([10])\n",
      "Parameter containing:\n",
      "-0.0432\n",
      " 0.0948\n",
      " 0.0547\n",
      " 0.1933\n",
      "-0.0653\n",
      "-0.1392\n",
      "-0.1988\n",
      " 0.0774\n",
      "-0.1776\n",
      "-0.2237\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with_params = model.parameters()\n",
    "for param, something in enumerate(with_params):\n",
    "    print(\"Layer number \", param)\n",
    "    print(\"Size of the layer\", something.size())\n",
    "    if param == 3:\n",
    "        print(something)\n",
    "    #print(something)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.2284\n",
      " 0.0000\n",
      " 3.5816\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Variable containing:\n",
      " 0.0000\n",
      " 0.2822\n",
      " 0.0835\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Variable containing:\n",
      " 0.0000\n",
      " 3.0092\n",
      " 0.6443\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Parameter containing:\n",
      "-0.0432\n",
      " 0.0948\n",
      " 0.0547\n",
      " 0.1933\n",
      "-0.0653\n",
      "-0.1392\n",
      "-0.1988\n",
      " 0.0774\n",
      "-0.1776\n",
      "-0.2237\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "with_params = model.parameters()\n",
    "\n",
    "model.count = 0\n",
    "for data, target in valid_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "\n",
    "for param, something in enumerate(with_params):\n",
    "    if param == 3:\n",
    "        print(something)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
