{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle \n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(trainset_new, batch_size=64, shuffle=True)\n",
    "# valid_loader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "trainset_imoprt = pickle.load(open(\"../data/kaggle/train_labeled.p\", \"rb\"))\n",
    "validset_import = pickle.load(open(\"../data/kaggle/validation.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset_imoprt, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validset_import, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_percentage(x):\n",
    "    y = x.data.numpy()\n",
    "    return len(y[np.where(y > 0)])*100./ y.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 20)\n",
    "        self.linear2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self,x ):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.dropout(F.relu(self.linear1(x)), p = 0.3)\n",
    "        print(\"Layer 1\", get_percentage(x))\n",
    "        x = F.dropout(F.relu(self.linear2(x)), p = 0.7)\n",
    "        print(\"Layer 2\", get_percentage(x))\n",
    "\n",
    "#         if self.count < 3:\n",
    "#             print(x[0])\n",
    "        self.count += 1\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CPU only training\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    layer_1_weights = 0\n",
    "    layer_2_weights = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += F.nll_loss(output, target).data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    layer_1_weights = model.state_dict()['linear1.weight']\n",
    "    layer_2_weights = model.state_dict()['linear2.weight']\n",
    "        \n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    return train_loss, layer_1_weights, layer_2_weights\n",
    "def test(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    layer_1_weights = 0\n",
    "    layer_2_weights = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "    layer_1_weights = model.state_dict()['linear1.weight']\n",
    "    layer_2_weights = model.state_dict()['linear2.weight']\n",
    "\n",
    "    test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(valid_loader.dataset),\n",
    "#         100. * correct / len(valid_loader.dataset)))\n",
    "    return test_loss, layer_1_weights, layer_2_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train outputs\n",
      "Layer 1 41.796875\n",
      "Layer 2 39.53125\n",
      "Layer 1 41.25\n",
      "Layer 2 41.875\n",
      "Layer 1 39.84375\n",
      "Layer 2 39.53125\n",
      "Layer 1 38.90625\n",
      "Layer 2 40.625\n",
      "Layer 1 37.8125\n",
      "Layer 2 42.1875\n",
      "Layer 1 37.65625\n",
      "Layer 2 40.15625\n",
      "Layer 1 39.921875\n",
      "Layer 2 39.84375\n",
      "Layer 1 38.59375\n",
      "Layer 2 39.6875\n",
      "Layer 1 37.578125\n",
      "Layer 2 39.21875\n",
      "Layer 1 37.03125\n",
      "Layer 2 39.375\n",
      "Layer 1 39.21875\n",
      "Layer 2 38.4375\n",
      "Layer 1 37.5\n",
      "Layer 2 39.375\n",
      "Layer 1 39.296875\n",
      "Layer 2 41.875\n",
      "Layer 1 38.984375\n",
      "Layer 2 41.25\n",
      "Layer 1 38.203125\n",
      "Layer 2 44.0625\n",
      "Layer 1 39.21875\n",
      "Layer 2 42.8125\n",
      "Layer 1 40.9375\n",
      "Layer 2 39.375\n",
      "Layer 1 39.609375\n",
      "Layer 2 40.9375\n",
      "Layer 1 39.21875\n",
      "Layer 2 41.875\n",
      "Layer 1 40.703125\n",
      "Layer 2 43.90625\n",
      "Layer 1 41.796875\n",
      "Layer 2 41.71875\n",
      "Layer 1 40.078125\n",
      "Layer 2 41.25\n",
      "Layer 1 38.359375\n",
      "Layer 2 40.15625\n",
      "Layer 1 41.5625\n",
      "Layer 2 42.34375\n",
      "Layer 1 41.953125\n",
      "Layer 2 42.1875\n",
      "Layer 1 41.015625\n",
      "Layer 2 43.4375\n",
      "Layer 1 41.40625\n",
      "Layer 2 40.625\n",
      "Layer 1 42.109375\n",
      "Layer 2 39.84375\n",
      "Layer 1 41.796875\n",
      "Layer 2 42.1875\n",
      "Layer 1 41.640625\n",
      "Layer 2 39.0625\n",
      "Layer 1 43.203125\n",
      "Layer 2 44.375\n",
      "Layer 1 41.25\n",
      "Layer 2 43.59375\n",
      "Layer 1 45.390625\n",
      "Layer 2 43.59375\n",
      "Layer 1 43.75\n",
      "Layer 2 40.0\n",
      "Layer 1 43.90625\n",
      "Layer 2 43.28125\n",
      "Layer 1 46.09375\n",
      "Layer 2 43.75\n",
      "Layer 1 45.703125\n",
      "Layer 2 41.09375\n",
      "Layer 1 47.03125\n",
      "Layer 2 43.90625\n",
      "Layer 1 45.0\n",
      "Layer 2 42.5\n",
      "Layer 1 46.640625\n",
      "Layer 2 43.4375\n",
      "Layer 1 46.875\n",
      "Layer 2 44.21875\n",
      "Layer 1 46.09375\n",
      "Layer 2 44.6875\n",
      "Layer 1 45.859375\n",
      "Layer 2 45.625\n",
      "Layer 1 45.859375\n",
      "Layer 2 46.25\n",
      "Layer 1 48.671875\n",
      "Layer 2 44.375\n",
      "Layer 1 49.53125\n",
      "Layer 2 43.75\n",
      "Layer 1 47.67857142857143\n",
      "Layer 2 41.25\n",
      "Test outputs\n",
      "Layer 1 47.265625\n",
      "Layer 2 43.28125\n",
      "Layer 1 50.3125\n",
      "Layer 2 42.65625\n",
      "Layer 1 48.984375\n",
      "Layer 2 42.65625\n",
      "Layer 1 50.46875\n",
      "Layer 2 45.3125\n",
      "Layer 1 48.203125\n",
      "Layer 2 40.15625\n",
      "Layer 1 47.578125\n",
      "Layer 2 42.34375\n",
      "Layer 1 46.015625\n",
      "Layer 2 42.65625\n",
      "Layer 1 50.46875\n",
      "Layer 2 43.59375\n",
      "Layer 1 47.5\n",
      "Layer 2 43.28125\n",
      "Layer 1 48.515625\n",
      "Layer 2 43.90625\n",
      "Layer 1 49.375\n",
      "Layer 2 45.15625\n",
      "Layer 1 47.8125\n",
      "Layer 2 43.75\n",
      "Layer 1 50.0\n",
      "Layer 2 44.21875\n",
      "Layer 1 46.40625\n",
      "Layer 2 44.84375\n",
      "Layer 1 47.734375\n",
      "Layer 2 42.03125\n",
      "Layer 1 49.921875\n",
      "Layer 2 42.96875\n",
      "Layer 1 49.140625\n",
      "Layer 2 45.78125\n",
      "Layer 1 49.921875\n",
      "Layer 2 41.875\n",
      "Layer 1 46.875\n",
      "Layer 2 43.59375\n",
      "Layer 1 50.15625\n",
      "Layer 2 42.5\n",
      "Layer 1 49.296875\n",
      "Layer 2 44.6875\n",
      "Layer 1 46.09375\n",
      "Layer 2 41.875\n",
      "Layer 1 47.65625\n",
      "Layer 2 43.4375\n",
      "Layer 1 47.96875\n",
      "Layer 2 43.59375\n",
      "Layer 1 48.828125\n",
      "Layer 2 42.65625\n",
      "Layer 1 47.265625\n",
      "Layer 2 41.875\n",
      "Layer 1 46.796875\n",
      "Layer 2 44.6875\n",
      "Layer 1 45.703125\n",
      "Layer 2 43.125\n",
      "Layer 1 48.90625\n",
      "Layer 2 43.125\n",
      "Layer 1 48.671875\n",
      "Layer 2 44.53125\n",
      "Layer 1 50.3125\n",
      "Layer 2 43.75\n",
      "Layer 1 47.1875\n",
      "Layer 2 44.21875\n",
      "Layer 1 49.765625\n",
      "Layer 2 45.625\n",
      "Layer 1 46.484375\n",
      "Layer 2 42.34375\n",
      "Layer 1 47.578125\n",
      "Layer 2 42.34375\n",
      "Layer 1 48.28125\n",
      "Layer 2 43.75\n",
      "Layer 1 49.6875\n",
      "Layer 2 41.5625\n",
      "Layer 1 48.203125\n",
      "Layer 2 46.71875\n",
      "Layer 1 49.453125\n",
      "Layer 2 40.3125\n",
      "Layer 1 48.59375\n",
      "Layer 2 41.40625\n",
      "Layer 1 48.28125\n",
      "Layer 2 45.46875\n",
      "Layer 1 47.5\n",
      "Layer 2 42.5\n",
      "Layer 1 48.359375\n",
      "Layer 2 46.25\n",
      "Layer 1 48.359375\n",
      "Layer 2 42.5\n",
      "Layer 1 44.21875\n",
      "Layer 2 42.8125\n",
      "Layer 1 47.734375\n",
      "Layer 2 42.5\n",
      "Layer 1 47.34375\n",
      "Layer 2 43.90625\n",
      "Layer 1 45.703125\n",
      "Layer 2 42.1875\n",
      "Layer 1 47.734375\n",
      "Layer 2 44.6875\n",
      "Layer 1 48.828125\n",
      "Layer 2 41.71875\n",
      "Layer 1 49.609375\n",
      "Layer 2 41.09375\n",
      "Layer 1 47.96875\n",
      "Layer 2 44.21875\n",
      "Layer 1 48.4375\n",
      "Layer 2 42.65625\n",
      "Layer 1 47.03125\n",
      "Layer 2 41.25\n",
      "Layer 1 49.140625\n",
      "Layer 2 43.90625\n",
      "Layer 1 48.515625\n",
      "Layer 2 39.21875\n",
      "Layer 1 50.0\n",
      "Layer 2 40.9375\n",
      "Layer 1 47.265625\n",
      "Layer 2 42.96875\n",
      "Layer 1 48.28125\n",
      "Layer 2 42.03125\n",
      "Layer 1 49.53125\n",
      "Layer 2 41.875\n",
      "Layer 1 49.21875\n",
      "Layer 2 42.34375\n",
      "Layer 1 48.125\n",
      "Layer 2 43.4375\n",
      "Layer 1 48.984375\n",
      "Layer 2 41.71875\n",
      "Layer 1 47.65625\n",
      "Layer 2 45.15625\n",
      "Layer 1 47.8125\n",
      "Layer 2 41.25\n",
      "Layer 1 47.578125\n",
      "Layer 2 45.3125\n",
      "Layer 1 49.0625\n",
      "Layer 2 42.34375\n",
      "Layer 1 47.109375\n",
      "Layer 2 44.53125\n",
      "Layer 1 46.5625\n",
      "Layer 2 42.5\n",
      "Layer 1 50.78125\n",
      "Layer 2 41.40625\n",
      "Layer 1 49.609375\n",
      "Layer 2 42.1875\n",
      "Layer 1 47.8125\n",
      "Layer 2 45.46875\n",
      "Layer 1 46.953125\n",
      "Layer 2 45.3125\n",
      "Layer 1 48.515625\n",
      "Layer 2 42.8125\n",
      "Layer 1 48.046875\n",
      "Layer 2 44.53125\n",
      "Layer 1 47.8125\n",
      "Layer 2 42.8125\n",
      "Layer 1 49.53125\n",
      "Layer 2 43.28125\n",
      "Layer 1 47.578125\n",
      "Layer 2 47.34375\n",
      "Layer 1 46.875\n",
      "Layer 2 41.71875\n",
      "Layer 1 46.484375\n",
      "Layer 2 45.3125\n",
      "Layer 1 46.015625\n",
      "Layer 2 41.09375\n",
      "Layer 1 50.546875\n",
      "Layer 2 45.78125\n",
      "Layer 1 48.203125\n",
      "Layer 2 41.25\n",
      "Layer 1 47.34375\n",
      "Layer 2 43.90625\n",
      "Layer 1 51.015625\n",
      "Layer 2 43.4375\n",
      "Layer 1 48.28125\n",
      "Layer 2 43.59375\n",
      "Layer 1 48.046875\n",
      "Layer 2 42.5\n",
      "Layer 1 49.21875\n",
      "Layer 2 40.3125\n",
      "Layer 1 49.375\n",
      "Layer 2 44.375\n",
      "Layer 1 50.625\n",
      "Layer 2 45.0\n",
      "Layer 1 46.25\n",
      "Layer 2 43.90625\n",
      "Layer 1 48.4375\n",
      "Layer 2 41.71875\n",
      "Layer 1 48.59375\n",
      "Layer 2 42.8125\n",
      "Layer 1 47.265625\n",
      "Layer 2 44.53125\n",
      "Layer 1 49.6875\n",
      "Layer 2 45.46875\n",
      "Layer 1 47.421875\n",
      "Layer 2 44.375\n",
      "Layer 1 48.203125\n",
      "Layer 2 44.375\n",
      "Layer 1 47.734375\n",
      "Layer 2 44.0625\n",
      "Layer 1 47.890625\n",
      "Layer 2 44.21875\n",
      "Layer 1 48.359375\n",
      "Layer 2 45.78125\n",
      "Layer 1 48.515625\n",
      "Layer 2 43.90625\n",
      "Layer 1 49.84375\n",
      "Layer 2 42.34375\n",
      "Layer 1 50.234375\n",
      "Layer 2 41.5625\n",
      "Layer 1 48.046875\n",
      "Layer 2 41.09375\n",
      "Layer 1 47.1875\n",
      "Layer 2 42.65625\n",
      "Layer 1 48.984375\n",
      "Layer 2 45.625\n",
      "Layer 1 50.625\n",
      "Layer 2 41.25\n",
      "Layer 1 48.515625\n",
      "Layer 2 42.8125\n",
      "Layer 1 45.390625\n",
      "Layer 2 44.375\n",
      "Layer 1 47.96875\n",
      "Layer 2 44.6875\n",
      "Layer 1 48.984375\n",
      "Layer 2 43.75\n",
      "Layer 1 46.171875\n",
      "Layer 2 44.21875\n",
      "Layer 1 47.265625\n",
      "Layer 2 42.34375\n",
      "Layer 1 49.21875\n",
      "Layer 2 41.71875\n",
      "Layer 1 48.359375\n",
      "Layer 2 44.6875\n",
      "Layer 1 47.109375\n",
      "Layer 2 46.71875\n",
      "Layer 1 49.6875\n",
      "Layer 2 42.34375\n",
      "Layer 1 49.84375\n",
      "Layer 2 42.1875\n",
      "Layer 1 49.84375\n",
      "Layer 2 45.15625\n",
      "Layer 1 46.640625\n",
      "Layer 2 44.21875\n",
      "Layer 1 47.96875\n",
      "Layer 2 41.71875\n",
      "Layer 1 47.578125\n",
      "Layer 2 42.5\n",
      "Layer 1 48.28125\n",
      "Layer 2 45.3125\n",
      "Layer 1 46.40625\n",
      "Layer 2 43.125\n",
      "Layer 1 47.1875\n",
      "Layer 2 42.96875\n",
      "Layer 1 49.765625\n",
      "Layer 2 43.75\n",
      "Layer 1 47.421875\n",
      "Layer 2 42.96875\n",
      "Layer 1 50.078125\n",
      "Layer 2 42.8125\n",
      "Layer 1 48.90625\n",
      "Layer 2 42.65625\n",
      "Layer 1 48.125\n",
      "Layer 2 44.375\n",
      "Layer 1 48.4375\n",
      "Layer 2 41.25\n",
      "Layer 1 47.890625\n",
      "Layer 2 42.34375\n",
      "Layer 1 48.4375\n",
      "Layer 2 43.75\n",
      "Layer 1 49.453125\n",
      "Layer 2 43.90625\n",
      "Layer 1 47.578125\n",
      "Layer 2 43.125\n",
      "Layer 1 48.203125\n",
      "Layer 2 42.5\n",
      "Layer 1 47.890625\n",
      "Layer 2 40.15625\n",
      "Layer 1 47.03125\n",
      "Layer 2 42.8125\n",
      "Layer 1 47.890625\n",
      "Layer 2 43.75\n",
      "Layer 1 49.921875\n",
      "Layer 2 43.4375\n",
      "Layer 1 47.96875\n",
      "Layer 2 43.125\n",
      "Layer 1 52.1875\n",
      "Layer 2 45.46875\n",
      "Layer 1 48.28125\n",
      "Layer 2 43.4375\n",
      "Layer 1 48.4375\n",
      "Layer 2 43.75\n",
      "Layer 1 49.84375\n",
      "Layer 2 42.03125\n",
      "Layer 1 48.28125\n",
      "Layer 2 41.09375\n",
      "Layer 1 46.015625\n",
      "Layer 2 43.90625\n",
      "Layer 1 48.515625\n",
      "Layer 2 42.96875\n",
      "Layer 1 48.75\n",
      "Layer 2 43.28125\n",
      "Layer 1 49.0625\n",
      "Layer 2 42.03125\n",
      "Layer 1 48.28125\n",
      "Layer 2 42.34375\n",
      "Layer 1 45.859375\n",
      "Layer 2 41.25\n",
      "Layer 1 48.203125\n",
      "Layer 2 43.75\n",
      "Layer 1 48.203125\n",
      "Layer 2 42.96875\n",
      "Layer 1 46.875\n",
      "Layer 2 44.0625\n",
      "Layer 1 49.609375\n",
      "Layer 2 42.65625\n",
      "Layer 1 51.5625\n",
      "Layer 2 41.875\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "train_layer_1 = []\n",
    "test_layer_1 = []\n",
    "train_layer_2 = []\n",
    "test_layer_2 = []\n",
    "model = SimpleNet()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    print(\"Train outputs\")\n",
    "\n",
    "    trainerror, trlayer_1, trlayer_2 = train(epoch)\n",
    "    print(\"Test outputs\")\n",
    "\n",
    "    testerror, tslayer_1, tslayer_2 = test(epoch, valid_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer number  0\n",
      "Size of the layer torch.Size([20, 784])\n",
      "Layer number  1\n",
      "Size of the layer torch.Size([20])\n",
      "Layer number  2\n",
      "Size of the layer torch.Size([10, 20])\n",
      "Layer number  3\n",
      "Size of the layer torch.Size([10])\n",
      "Parameter containing:\n",
      "-0.0432\n",
      " 0.0948\n",
      " 0.0547\n",
      " 0.1933\n",
      "-0.0653\n",
      "-0.1392\n",
      "-0.1988\n",
      " 0.0774\n",
      "-0.1776\n",
      "-0.2237\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with_params = model.parameters()\n",
    "for param, something in enumerate(with_params):\n",
    "    print(\"Layer number \", param)\n",
    "    print(\"Size of the layer\", something.size())\n",
    "    if param == 3:\n",
    "        print(something)\n",
    "    #print(something)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.2284\n",
      " 0.0000\n",
      " 3.5816\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Variable containing:\n",
      " 0.0000\n",
      " 0.2822\n",
      " 0.0835\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Variable containing:\n",
      " 0.0000\n",
      " 3.0092\n",
      " 0.6443\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Parameter containing:\n",
      "-0.0432\n",
      " 0.0948\n",
      " 0.0547\n",
      " 0.1933\n",
      "-0.0653\n",
      "-0.1392\n",
      "-0.1988\n",
      " 0.0774\n",
      "-0.1776\n",
      "-0.2237\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "with_params = model.parameters()\n",
    "\n",
    "model.count = 0\n",
    "for data, target in valid_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "\n",
    "for param, something in enumerate(with_params):\n",
    "    if param == 3:\n",
    "        print(something)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
