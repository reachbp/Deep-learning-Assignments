{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                ])\n",
    "trainset_labeled_import = pickle.load(open(\"../data/kaggle/train_labeled.p\", \"rb\"))\n",
    "trainset_unlabeled_import = pickle.load(open(\"../data/kaggle/train_unlabeled.p\", \"rb\"))\n",
    "validset_import = pickle.load(open(\"../data/kaggle/validation.p\", \"rb\"))\n",
    "train_labeled_loader = torch.utils.data.DataLoader(trainset_labeled_import, batch_size=32, shuffle=True)\n",
    "train_unlabeled_loader = torch.utils.data.DataLoader(trainset_unlabeled_import, batch_size=256,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "train_unlabeled_loader.dataset.train_labels = [-1 for i in range(len(train_unlabeled_loader.dataset.train_data))]\n",
    "valid_loader = torch.utils.data.DataLoader(validset_import, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.3540 -2.3185 -2.3540 -2.1871 -2.3540 -2.3540 -2.3540 -2.3097 -2.3540 -2.1192\n",
       "-2.3662 -2.3662 -2.3496 -2.1158 -2.3662 -2.3662 -2.3662 -2.1854 -2.3662 -2.2202\n",
       "-2.3395 -2.3395 -2.3395 -2.1867 -2.3395 -2.2995 -2.3395 -2.2750 -2.3395 -2.2413\n",
       "-2.3884 -2.2542 -2.3884 -2.2824 -2.3884 -2.3884 -2.3884 -2.2192 -2.3884 -2.0124\n",
       "-2.3977 -2.2243 -2.3977 -2.1247 -2.3977 -2.3730 -2.3977 -2.1489 -2.3611 -2.2579\n",
       "-2.3635 -2.3327 -1.9843 -2.3276 -2.4016 -2.4016 -2.4016 -2.2453 -2.4016 -2.2473\n",
       "-2.2541 -2.3334 -2.2121 -2.3334 -2.3334 -2.3334 -2.3334 -2.2370 -2.3334 -2.3334\n",
       "-2.3570 -2.3570 -2.3570 -2.3570 -2.3570 -2.3570 -2.1721 -2.2473 -2.3570 -2.1418\n",
       "-2.2479 -2.3086 -2.2341 -2.3485 -2.2541 -2.3485 -2.3485 -2.2504 -2.3485 -2.3485\n",
       "-2.3753 -2.3253 -2.1638 -2.1836 -2.4261 -2.4261 -2.4261 -2.2003 -2.4261 -2.1418\n",
       "-2.3386 -2.3358 -2.3232 -2.3307 -2.3386 -2.3386 -2.1604 -2.2763 -2.3386 -2.2609\n",
       "-2.3500 -2.3500 -2.3069 -2.1984 -2.3239 -2.3500 -2.3360 -2.1369 -2.3500 -2.3500\n",
       "-2.3385 -2.3385 -2.2214 -2.1220 -2.3385 -2.3385 -2.3385 -2.3385 -2.3385 -2.3385\n",
       "-2.3326 -2.1123 -2.3245 -2.3326 -2.3326 -2.3326 -2.3326 -2.3326 -2.3326 -2.2835\n",
       "-2.3575 -2.1898 -2.3510 -2.3045 -2.3575 -2.3575 -2.3575 -2.1548 -2.3575 -2.2653\n",
       "-2.3359 -2.2845 -2.1381 -2.3359 -2.3359 -2.3359 -2.3359 -2.3100 -2.3359 -2.2954\n",
       "-2.3334 -2.2513 -2.2854 -2.3334 -2.3334 -2.3334 -2.3334 -2.3334 -2.3334 -2.1695\n",
       "-2.3253 -2.4082 -2.1670 -2.4278 -2.4278 -2.3634 -2.4278 -2.1060 -2.3805 -2.0816\n",
       "-2.3789 -2.3789 -2.3188 -2.0603 -2.3789 -2.3789 -2.2396 -2.3789 -2.3789 -2.1914\n",
       "-2.3268 -2.3268 -2.3268 -2.3268 -2.3268 -2.3268 -2.2927 -2.1779 -2.3268 -2.2781\n",
       "-2.2306 -2.3483 -2.1186 -2.3760 -2.3760 -2.3760 -2.3760 -2.2228 -2.3760 -2.2644\n",
       "-2.3545 -2.2733 -2.3545 -2.3540 -2.3545 -2.3545 -2.2226 -2.3545 -2.3545 -2.0866\n",
       "-2.3498 -2.3498 -2.3124 -2.1598 -2.3498 -2.3498 -2.3498 -2.2931 -2.3498 -2.1862\n",
       "-2.3394 -2.2258 -2.3394 -2.3394 -2.3394 -2.3394 -2.3394 -2.3394 -2.3106 -2.1362\n",
       "-2.3862 -2.3862 -2.3862 -2.1195 -2.3862 -2.3862 -2.3595 -2.2844 -2.3862 -2.0269\n",
       "-2.3473 -2.3473 -2.2615 -2.0638 -2.3473 -2.3473 -2.3473 -2.3473 -2.3473 -2.3079\n",
       "-2.4101 -2.4101 -2.3521 -2.1101 -2.4101 -2.4101 -2.3544 -2.1449 -2.4101 -2.0994\n",
       "-2.3179 -2.2997 -2.2431 -2.2746 -2.3263 -2.3667 -2.3667 -2.2572 -2.2201 -2.3667\n",
       "-2.3978 -2.3978 -2.2214 -2.2211 -2.3978 -2.2905 -2.3978 -2.0976 -2.3978 -2.2584\n",
       "-2.3468 -2.3468 -2.3468 -2.3468 -2.3468 -2.3468 -2.1976 -2.3457 -2.3468 -2.0921\n",
       "-2.3547 -2.3547 -2.2149 -2.1790 -2.3547 -2.3547 -2.3357 -2.3547 -2.3547 -2.1947\n",
       "-2.3266 -2.4288 -2.2776 -2.3427 -2.4288 -2.3429 -2.1982 -2.1616 -2.4288 -2.1443\n",
       "[torch.FloatTensor of size 32x10]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d(0.3)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        print(x.size())\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x)\n",
    "model = Net()\n",
    "a = torch.randn(32, 1, 28, 28)\n",
    "model.forward(Variable(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 13, 13])\n",
      "torch.Size([32, 64, 5, 5])\n",
      "torch.Size([32, 64, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.2338 -2.3471 -2.4053 -2.3392 -2.4053 -2.4053 -2.4053 -2.0519 -2.1661 -2.3355\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NetBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetBN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=(1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, padding=(1, 1))\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "        self.conv1_drop = nn.Dropout2d(0.2)\n",
    "        self.conv2_drop = nn.Dropout2d(0.3)\n",
    "        self.conv3_drop = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(32 * 128, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_drop(F.relu(F.max_pool2d(self.conv1(x), (2,2))))\n",
    "        print(x.size())\n",
    "\n",
    "        x = self.conv2_drop(F.relu(F.max_pool2d(self.conv2(x), (2,2))))\n",
    "        print(x.size())\n",
    "\n",
    "        x = self.conv3_drop(F.relu(F.max_pool2d(self.conv3(x), (2,2))))\n",
    "        print(x.size())\n",
    "        x = x.view(-1, 32 * 128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = NetBN()\n",
    "a = torch.randn(32, 1, 28, 28)\n",
    "model.forward(Variable(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = NetBN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=.01, momentum=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_labeled_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "#         loss = my_criterion.forward(output, target, Variable(torch.LongTensor(epoch)), Variable(torch.LongTensor(1)))\n",
    "#         my_criterion.backward(loss)\n",
    "        print(data.size())\n",
    "        print(output.data.size(), target.data.size())\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Labeled Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_labeled_loader.dataset),\n",
    "                       100. * batch_idx / len(train_labeled_loader), loss.data[0]))\n",
    "\n",
    "    for batch_idx, (data,_) in enumerate(train_unlabeled_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target = Variable(torch.LongTensor(output.data.max(1)[1].numpy().reshape(-1)))\n",
    "#         loss = my_criterion.forward(output, target, Variable(torch.LongTensor(epoch)), Variable(torch.LongTensor(2)))\n",
    "#         my_criterion.backward(loss)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Unlabeled Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_unlabeled_loader.dataset),\n",
    "                       100. * batch_idx / len(train_unlabeled_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += my_criterion.forward(output, target, Variable(epoch), Variable(torch.LongTensor(1))).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 1, 1])\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([1, 10]) torch.Size([32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /Users/soumith/anaconda/conda-bld/pytorch-0.1.7_1485439972367/work/torch/lib/THNN/generic/ClassNLLCriterion.c:50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-2208a0a6210b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-167-53192ca874d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pratheeksha/anaconda3/envs/dlpy35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \"\"\"\n\u001b[0;32m--> 419\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pratheeksha/anaconda3/envs/dlpy35/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         getattr(self._backend, update_output.name)(self._backend.library_state, input, target,\n\u001b[0;32m---> 41\u001b[0;31m             output, *self.additional_args)\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /Users/soumith/anaconda/conda-bld/pytorch-0.1.7_1485439972367/work/torch/lib/THNN/generic/ClassNLLCriterion.c:50"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train(epoch)\n",
    "    validate(epoch, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = pickle.load(open(\"../data/kaggle/test.p\", \"rb\"))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCriterion(torch.autograd.Function):\n",
    "    def __init__(self):\n",
    "        self.alpha = .0005\n",
    "    \n",
    "    def forward(self, input, target, epoch, isLabeled):\n",
    "        loss = F.cross_entropy(input, target)\n",
    "\n",
    "        self.save_for_backward(input, target, epoch, isLabeled, loss)\n",
    "        print(self.saved_tensors)\n",
    "        if (isLabeled.data > 0).all():\n",
    "\n",
    "            return Variable(loss.data * self.alpha * epoch.data)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "       \n",
    "        input, target, epoch, isLabeled, loss, = self.saved_tensors\n",
    "        grad_input = loss.backward() \n",
    "        return grad_input\n",
    "my_criterion = MyCriterion()\n",
    "x = Variable(torch.randn(11, 10).type(torch.FloatTensor))\n",
    "y = Variable(torch.range(1,6, .5).type(torch.LongTensor))\n",
    "\n",
    "a = torch.from_numpy(np.array([0]))\n",
    "b = torch.from_numpy(np.array([1]))\n",
    "c = torch.from_numpy(np.array([10.0]))\n",
    "\n",
    "print(x)\n",
    "# print(torch.from_numpy(np.array([10])))\n",
    "first_loss  = my_criterion.forward(x, y, Variable(c.float()),  Variable(a))\n",
    "print(my_criterion.backward(first_loss))\n",
    "\n",
    "second_loss = my_criterion.forward(x, y, Variable(c.float()),  Variable(b))\n",
    "print(my_criterion.backward(second_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_predict = np.array([])\n",
    "model.eval()\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    temp = output.data.max(1)[1].numpy().reshape(-1)\n",
    "    \n",
    "    label_predict = np.concatenate((label_predict, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_predict\n",
    "\n",
    "predict_label = pd.DataFrame(label_predict, columns=['label'], dtype=int)\n",
    "predict_label.reset_index(inplace=True)\n",
    "predict_label.rename(columns={'index': 'ID'}, inplace=True)\n",
    "\n",
    "predict_label.head()\n",
    "\n",
    "predict_label.to_csv('../data/kaggle/sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
