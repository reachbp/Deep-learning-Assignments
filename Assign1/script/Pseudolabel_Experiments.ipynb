{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sub.subMNIST'>\n",
      "<class 'sub.subMNIST'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_unlabeled_loader.dataset))\n",
    "print(type(train_labeled_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sub import subMNIST       # testing the subclass of MNIST dataset\n",
    "\n",
    "trainset_original = datasets.MNIST('../data', train=True, download=True,\n",
    "                                  transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label_index = []\n",
    "valid_label_index = []\n",
    "for i in range(10):\n",
    "    train_label_list = trainset_original.train_labels.numpy()\n",
    "    label_index = np.where(train_label_list == i)[0]\n",
    "    label_subindex = list(label_index[:300])\n",
    "    valid_subindex = list(label_index[300: 1000 + 300])\n",
    "    train_label_index += label_subindex\n",
    "    valid_label_index += valid_subindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_np = trainset_original.train_data.numpy()\n",
    "trainset_label_np = trainset_original.train_labels.numpy()\n",
    "train_data_sub = torch.from_numpy(trainset_np[train_label_index])\n",
    "train_labels_sub = torch.from_numpy(trainset_label_np[train_label_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_unlabel_index = []\n",
    "for i in range(60000):\n",
    "    if i in train_label_index or i in valid_label_index:\n",
    "        pass\n",
    "    else:\n",
    "        train_unlabel_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_np = trainset_original.train_data.numpy()\n",
    "trainset_label_np = trainset_original.train_labels.numpy()\n",
    "train_data_sub_unl = torch.from_numpy(trainset_np[train_unlabel_index])\n",
    "train_labels_sub_unl = torch.from_numpy(trainset_label_np[train_unlabel_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "trainset_new_unl = subMNIST(root='./data', train=True, download=True, transform=transform, k=47000)\n",
    "trainset_new_unl.train_data.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(trainset_new_unl, open(\"../data/kaggle/train_unlabeled.p\", \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                ])\n",
    "trainset_labeled_import = pickle.load(open(\"../data/kaggle/train_labeled.p\", \"rb\"))\n",
    "trainset_unlabeled_import = pickle.load(open(\"../data/kaggle/train_unlabeled.p\", \"rb\"))\n",
    "validset_import = pickle.load(open(\"../data/kaggle/validation.p\", \"rb\"))\n",
    "train_labeled_loader = torch.utils.data.DataLoader(trainset_labeled_import, batch_size=32, shuffle=True)\n",
    "train_unlabeled_loader = torch.utils.data.DataLoader(trainset_unlabeled_import, batch_size=256,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "train_unlabeled_loader.dataset.train_labels = [-1 for i in range(len(train_unlabeled_loader.dataset.train_data))]\n",
    "valid_loader = torch.utils.data.DataLoader(validset_import, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d(0.3)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=.01, momentum=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_labeled_loader):\n",
    "\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Labeled Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_labeled_loader.dataset),\n",
    "                       100. * batch_idx / len(train_labeled_loader), loss.data[0]))\n",
    "\n",
    "    for batch_idx, (data,_) in enumerate(train_unlabeled_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target = Variable(torch.LongTensor(output.data.max(1)[1].numpy().reshape(-1)))\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Unlabeled Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_unlabeled_loader.dataset),\n",
    "                       100. * batch_idx / len(train_unlabeled_loader), loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labeled Epoch: 1 [0/3000 (0%)]\tLoss: 2.240440\n",
      "Train Labeled Epoch: 1 [320/3000 (11%)]\tLoss: 2.365440\n",
      "Train Labeled Epoch: 1 [640/3000 (21%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 1 [960/3000 (32%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 1 [1280/3000 (43%)]\tLoss: 2.334402\n",
      "Train Labeled Epoch: 1 [1600/3000 (53%)]\tLoss: 2.256057\n",
      "Train Labeled Epoch: 1 [1920/3000 (64%)]\tLoss: 2.302936\n",
      "Train Labeled Epoch: 1 [2240/3000 (74%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 1 [2560/3000 (85%)]\tLoss: 2.318558\n",
      "Train Labeled Epoch: 1 [2880/3000 (96%)]\tLoss: 2.334189\n",
      "Train Unlabeled Epoch: 1 [0/47000 (0%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 1 [2560/47000 (5%)]\tLoss: 1.865455\n",
      "Train Unlabeled Epoch: 1 [5120/47000 (11%)]\tLoss: 1.865590\n",
      "Train Unlabeled Epoch: 1 [7680/47000 (16%)]\tLoss: 1.865463\n",
      "Train Unlabeled Epoch: 1 [10240/47000 (22%)]\tLoss: 1.865495\n",
      "Train Unlabeled Epoch: 1 [12800/47000 (27%)]\tLoss: 1.865751\n",
      "Train Unlabeled Epoch: 1 [15360/47000 (33%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 1 [17920/47000 (38%)]\tLoss: 1.865578\n",
      "Train Unlabeled Epoch: 1 [20480/47000 (43%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 1 [23040/47000 (49%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 1 [25600/47000 (54%)]\tLoss: 1.865459\n",
      "Train Unlabeled Epoch: 1 [28160/47000 (60%)]\tLoss: 1.865468\n",
      "Train Unlabeled Epoch: 1 [30720/47000 (65%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 1 [33280/47000 (71%)]\tLoss: 1.865474\n",
      "Train Unlabeled Epoch: 1 [35840/47000 (76%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 1 [38400/47000 (82%)]\tLoss: 1.865487\n",
      "Train Unlabeled Epoch: 1 [40960/47000 (87%)]\tLoss: 1.865460\n",
      "Train Unlabeled Epoch: 1 [43520/47000 (92%)]\tLoss: 1.865509\n",
      "Train Unlabeled Epoch: 1 [46080/47000 (98%)]\tLoss: 1.865450\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 2 [0/3000 (0%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 2 [320/3000 (11%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 2 [640/3000 (21%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 2 [960/3000 (32%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 2 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 2 [1600/3000 (53%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 2 [1920/3000 (64%)]\tLoss: 2.256065\n",
      "Train Labeled Epoch: 2 [2240/3000 (74%)]\tLoss: 2.302936\n",
      "Train Labeled Epoch: 2 [2560/3000 (85%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 2 [2880/3000 (96%)]\tLoss: 2.318565\n",
      "Train Unlabeled Epoch: 2 [0/47000 (0%)]\tLoss: 1.865475\n",
      "Train Unlabeled Epoch: 2 [2560/47000 (5%)]\tLoss: 1.865499\n",
      "Train Unlabeled Epoch: 2 [5120/47000 (11%)]\tLoss: 1.865515\n",
      "Train Unlabeled Epoch: 2 [7680/47000 (16%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 2 [10240/47000 (22%)]\tLoss: 1.865604\n",
      "Train Unlabeled Epoch: 2 [12800/47000 (27%)]\tLoss: 1.865464\n",
      "Train Unlabeled Epoch: 2 [15360/47000 (33%)]\tLoss: 1.865639\n",
      "Train Unlabeled Epoch: 2 [17920/47000 (38%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 2 [20480/47000 (43%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 2 [23040/47000 (49%)]\tLoss: 1.865468\n",
      "Train Unlabeled Epoch: 2 [25600/47000 (54%)]\tLoss: 1.865500\n",
      "Train Unlabeled Epoch: 2 [28160/47000 (60%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 2 [30720/47000 (65%)]\tLoss: 1.865481\n",
      "Train Unlabeled Epoch: 2 [33280/47000 (71%)]\tLoss: 1.865575\n",
      "Train Unlabeled Epoch: 2 [35840/47000 (76%)]\tLoss: 1.865487\n",
      "Train Unlabeled Epoch: 2 [38400/47000 (82%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 2 [40960/47000 (87%)]\tLoss: 1.865463\n",
      "Train Unlabeled Epoch: 2 [43520/47000 (92%)]\tLoss: 1.865478\n",
      "Train Unlabeled Epoch: 2 [46080/47000 (98%)]\tLoss: 1.865500\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 3 [0/3000 (0%)]\tLoss: 2.271687\n",
      "Train Labeled Epoch: 3 [320/3000 (11%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 3 [640/3000 (21%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 3 [960/3000 (32%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 3 [1280/3000 (43%)]\tLoss: 2.365440\n",
      "Train Labeled Epoch: 3 [1600/3000 (53%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 3 [1920/3000 (64%)]\tLoss: 2.240589\n",
      "Train Labeled Epoch: 3 [2240/3000 (74%)]\tLoss: 2.334210\n",
      "Train Labeled Epoch: 3 [2560/3000 (85%)]\tLoss: 2.334188\n",
      "Train Labeled Epoch: 3 [2880/3000 (96%)]\tLoss: 2.318565\n",
      "Train Unlabeled Epoch: 3 [0/47000 (0%)]\tLoss: 1.865466\n",
      "Train Unlabeled Epoch: 3 [2560/47000 (5%)]\tLoss: 1.865522\n",
      "Train Unlabeled Epoch: 3 [5120/47000 (11%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 3 [7680/47000 (16%)]\tLoss: 1.865545\n",
      "Train Unlabeled Epoch: 3 [10240/47000 (22%)]\tLoss: 1.865930\n",
      "Train Unlabeled Epoch: 3 [12800/47000 (27%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 3 [15360/47000 (33%)]\tLoss: 1.865479\n",
      "Train Unlabeled Epoch: 3 [17920/47000 (38%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 3 [20480/47000 (43%)]\tLoss: 1.865455\n",
      "Train Unlabeled Epoch: 3 [23040/47000 (49%)]\tLoss: 1.865515\n",
      "Train Unlabeled Epoch: 3 [25600/47000 (54%)]\tLoss: 1.865455\n",
      "Train Unlabeled Epoch: 3 [28160/47000 (60%)]\tLoss: 1.865466\n",
      "Train Unlabeled Epoch: 3 [30720/47000 (65%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 3 [33280/47000 (71%)]\tLoss: 1.865450\n",
      "Train Unlabeled Epoch: 3 [35840/47000 (76%)]\tLoss: 1.865458\n",
      "Train Unlabeled Epoch: 3 [38400/47000 (82%)]\tLoss: 1.865687\n",
      "Train Unlabeled Epoch: 3 [40960/47000 (87%)]\tLoss: 1.865483\n",
      "Train Unlabeled Epoch: 3 [43520/47000 (92%)]\tLoss: 1.865497\n",
      "Train Unlabeled Epoch: 3 [46080/47000 (98%)]\tLoss: 1.865478\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 4 [0/3000 (0%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 4 [320/3000 (11%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 4 [640/3000 (21%)]\tLoss: 2.318563\n",
      "Train Labeled Epoch: 4 [960/3000 (32%)]\tLoss: 2.302939\n",
      "Train Labeled Epoch: 4 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 4 [1600/3000 (53%)]\tLoss: 2.318844\n",
      "Train Labeled Epoch: 4 [1920/3000 (64%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 4 [2240/3000 (74%)]\tLoss: 2.271690\n",
      "Train Labeled Epoch: 4 [2560/3000 (85%)]\tLoss: 2.334199\n",
      "Train Labeled Epoch: 4 [2880/3000 (96%)]\tLoss: 2.302940\n",
      "Train Unlabeled Epoch: 4 [0/47000 (0%)]\tLoss: 1.865458\n",
      "Train Unlabeled Epoch: 4 [2560/47000 (5%)]\tLoss: 1.865514\n",
      "Train Unlabeled Epoch: 4 [5120/47000 (11%)]\tLoss: 1.865575\n",
      "Train Unlabeled Epoch: 4 [7680/47000 (16%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 4 [10240/47000 (22%)]\tLoss: 1.865502\n",
      "Train Unlabeled Epoch: 4 [12800/47000 (27%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 4 [15360/47000 (33%)]\tLoss: 1.865468\n",
      "Train Unlabeled Epoch: 4 [17920/47000 (38%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 4 [20480/47000 (43%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 4 [23040/47000 (49%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 4 [25600/47000 (54%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 4 [28160/47000 (60%)]\tLoss: 1.865542\n",
      "Train Unlabeled Epoch: 4 [30720/47000 (65%)]\tLoss: 1.866064\n",
      "Train Unlabeled Epoch: 4 [33280/47000 (71%)]\tLoss: 1.865475\n",
      "Train Unlabeled Epoch: 4 [35840/47000 (76%)]\tLoss: 1.865530\n",
      "Train Unlabeled Epoch: 4 [38400/47000 (82%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 4 [40960/47000 (87%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 4 [43520/47000 (92%)]\tLoss: 1.865475\n",
      "Train Unlabeled Epoch: 4 [46080/47000 (98%)]\tLoss: 1.865664\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 5 [0/3000 (0%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 5 [320/3000 (11%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 5 [640/3000 (21%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 5 [960/3000 (32%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 5 [1280/3000 (43%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 5 [1600/3000 (53%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 5 [1920/3000 (64%)]\tLoss: 2.349808\n",
      "Train Labeled Epoch: 5 [2240/3000 (74%)]\tLoss: 2.365440\n",
      "Train Labeled Epoch: 5 [2560/3000 (85%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 5 [2880/3000 (96%)]\tLoss: 2.302940\n",
      "Train Unlabeled Epoch: 5 [0/47000 (0%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 5 [2560/47000 (5%)]\tLoss: 1.865532\n",
      "Train Unlabeled Epoch: 5 [5120/47000 (11%)]\tLoss: 1.865553\n",
      "Train Unlabeled Epoch: 5 [7680/47000 (16%)]\tLoss: 1.865588\n",
      "Train Unlabeled Epoch: 5 [10240/47000 (22%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 5 [12800/47000 (27%)]\tLoss: 1.865470\n",
      "Train Unlabeled Epoch: 5 [15360/47000 (33%)]\tLoss: 1.865861\n",
      "Train Unlabeled Epoch: 5 [17920/47000 (38%)]\tLoss: 1.865467\n",
      "Train Unlabeled Epoch: 5 [20480/47000 (43%)]\tLoss: 1.865547\n",
      "Train Unlabeled Epoch: 5 [23040/47000 (49%)]\tLoss: 1.865538\n",
      "Train Unlabeled Epoch: 5 [25600/47000 (54%)]\tLoss: 1.865690\n",
      "Train Unlabeled Epoch: 5 [28160/47000 (60%)]\tLoss: 1.865465\n",
      "Train Unlabeled Epoch: 5 [30720/47000 (65%)]\tLoss: 1.865455\n",
      "Train Unlabeled Epoch: 5 [33280/47000 (71%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 5 [35840/47000 (76%)]\tLoss: 1.865476\n",
      "Train Unlabeled Epoch: 5 [38400/47000 (82%)]\tLoss: 1.865452\n",
      "Train Unlabeled Epoch: 5 [40960/47000 (87%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 5 [43520/47000 (92%)]\tLoss: 1.865655\n",
      "Train Unlabeled Epoch: 5 [46080/47000 (98%)]\tLoss: 1.865460\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 6 [0/3000 (0%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 6 [320/3000 (11%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 6 [640/3000 (21%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 6 [960/3000 (32%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 6 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 6 [1600/3000 (53%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 6 [1920/3000 (64%)]\tLoss: 2.302938\n",
      "Train Labeled Epoch: 6 [2240/3000 (74%)]\tLoss: 2.302938\n",
      "Train Labeled Epoch: 6 [2560/3000 (85%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 6 [2880/3000 (96%)]\tLoss: 2.318565\n",
      "Train Unlabeled Epoch: 6 [0/47000 (0%)]\tLoss: 1.865453\n",
      "Train Unlabeled Epoch: 6 [2560/47000 (5%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 6 [5120/47000 (11%)]\tLoss: 1.865464\n",
      "Train Unlabeled Epoch: 6 [7680/47000 (16%)]\tLoss: 1.865477\n",
      "Train Unlabeled Epoch: 6 [10240/47000 (22%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 6 [12800/47000 (27%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 6 [15360/47000 (33%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 6 [17920/47000 (38%)]\tLoss: 1.865576\n",
      "Train Unlabeled Epoch: 6 [20480/47000 (43%)]\tLoss: 1.865454\n",
      "Train Unlabeled Epoch: 6 [23040/47000 (49%)]\tLoss: 1.865633\n",
      "Train Unlabeled Epoch: 6 [25600/47000 (54%)]\tLoss: 1.865472\n",
      "Train Unlabeled Epoch: 6 [28160/47000 (60%)]\tLoss: 1.865620\n",
      "Train Unlabeled Epoch: 6 [30720/47000 (65%)]\tLoss: 1.865572\n",
      "Train Unlabeled Epoch: 6 [33280/47000 (71%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 6 [35840/47000 (76%)]\tLoss: 1.865475\n",
      "Train Unlabeled Epoch: 6 [38400/47000 (82%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 6 [40960/47000 (87%)]\tLoss: 1.865501\n",
      "Train Unlabeled Epoch: 6 [43520/47000 (92%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 6 [46080/47000 (98%)]\tLoss: 1.865526\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 7 [0/3000 (0%)]\tLoss: 2.287314\n",
      "Train Labeled Epoch: 7 [320/3000 (11%)]\tLoss: 2.302937\n",
      "Train Labeled Epoch: 7 [640/3000 (21%)]\tLoss: 2.302938\n",
      "Train Labeled Epoch: 7 [960/3000 (32%)]\tLoss: 2.318737\n",
      "Train Labeled Epoch: 7 [1280/3000 (43%)]\tLoss: 2.287317\n",
      "Train Labeled Epoch: 7 [1600/3000 (53%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 7 [1920/3000 (64%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 7 [2240/3000 (74%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 7 [2560/3000 (85%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 7 [2880/3000 (96%)]\tLoss: 2.287315\n",
      "Train Unlabeled Epoch: 7 [0/47000 (0%)]\tLoss: 1.865465\n",
      "Train Unlabeled Epoch: 7 [2560/47000 (5%)]\tLoss: 1.865547\n",
      "Train Unlabeled Epoch: 7 [5120/47000 (11%)]\tLoss: 1.865912\n",
      "Train Unlabeled Epoch: 7 [7680/47000 (16%)]\tLoss: 1.865509\n",
      "Train Unlabeled Epoch: 7 [10240/47000 (22%)]\tLoss: 1.865766\n",
      "Train Unlabeled Epoch: 7 [12800/47000 (27%)]\tLoss: 1.865531\n",
      "Train Unlabeled Epoch: 7 [15360/47000 (33%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 7 [17920/47000 (38%)]\tLoss: 1.866472\n",
      "Train Unlabeled Epoch: 7 [20480/47000 (43%)]\tLoss: 1.865527\n",
      "Train Unlabeled Epoch: 7 [23040/47000 (49%)]\tLoss: 1.865458\n",
      "Train Unlabeled Epoch: 7 [25600/47000 (54%)]\tLoss: 1.865636\n",
      "Train Unlabeled Epoch: 7 [28160/47000 (60%)]\tLoss: 1.865493\n",
      "Train Unlabeled Epoch: 7 [30720/47000 (65%)]\tLoss: 1.865554\n",
      "Train Unlabeled Epoch: 7 [33280/47000 (71%)]\tLoss: 1.865481\n",
      "Train Unlabeled Epoch: 7 [35840/47000 (76%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 7 [38400/47000 (82%)]\tLoss: 1.865614\n",
      "Train Unlabeled Epoch: 7 [40960/47000 (87%)]\tLoss: 1.865559\n",
      "Train Unlabeled Epoch: 7 [43520/47000 (92%)]\tLoss: 1.865541\n",
      "Train Unlabeled Epoch: 7 [46080/47000 (98%)]\tLoss: 1.865471\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 8 [0/3000 (0%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 8 [320/3000 (11%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 8 [640/3000 (21%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 8 [960/3000 (32%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 8 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 8 [1600/3000 (53%)]\tLoss: 2.349811\n",
      "Train Labeled Epoch: 8 [1920/3000 (64%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 8 [2240/3000 (74%)]\tLoss: 2.318555\n",
      "Train Labeled Epoch: 8 [2560/3000 (85%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 8 [2880/3000 (96%)]\tLoss: 2.287314\n",
      "Train Unlabeled Epoch: 8 [0/47000 (0%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 8 [2560/47000 (5%)]\tLoss: 1.865476\n",
      "Train Unlabeled Epoch: 8 [5120/47000 (11%)]\tLoss: 1.865675\n",
      "Train Unlabeled Epoch: 8 [7680/47000 (16%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 8 [10240/47000 (22%)]\tLoss: 1.865531\n",
      "Train Unlabeled Epoch: 8 [12800/47000 (27%)]\tLoss: 1.865519\n",
      "Train Unlabeled Epoch: 8 [15360/47000 (33%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 8 [17920/47000 (38%)]\tLoss: 1.865578\n",
      "Train Unlabeled Epoch: 8 [20480/47000 (43%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 8 [23040/47000 (49%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 8 [25600/47000 (54%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 8 [28160/47000 (60%)]\tLoss: 1.865456\n",
      "Train Unlabeled Epoch: 8 [30720/47000 (65%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 8 [33280/47000 (71%)]\tLoss: 1.865596\n",
      "Train Unlabeled Epoch: 8 [35840/47000 (76%)]\tLoss: 1.865656\n",
      "Train Unlabeled Epoch: 8 [38400/47000 (82%)]\tLoss: 1.865465\n",
      "Train Unlabeled Epoch: 8 [40960/47000 (87%)]\tLoss: 1.865515\n",
      "Train Unlabeled Epoch: 8 [43520/47000 (92%)]\tLoss: 1.865481\n",
      "Train Unlabeled Epoch: 8 [46080/47000 (98%)]\tLoss: 1.865455\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 9 [0/3000 (0%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 9 [320/3000 (11%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 9 [640/3000 (21%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 9 [960/3000 (32%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 9 [1280/3000 (43%)]\tLoss: 2.349878\n",
      "Train Labeled Epoch: 9 [1600/3000 (53%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 9 [1920/3000 (64%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 9 [2240/3000 (74%)]\tLoss: 2.318561\n",
      "Train Labeled Epoch: 9 [2560/3000 (85%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 9 [2880/3000 (96%)]\tLoss: 2.302940\n",
      "Train Unlabeled Epoch: 9 [0/47000 (0%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 9 [2560/47000 (5%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 9 [5120/47000 (11%)]\tLoss: 1.865450\n",
      "Train Unlabeled Epoch: 9 [7680/47000 (16%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 9 [10240/47000 (22%)]\tLoss: 1.865480\n",
      "Train Unlabeled Epoch: 9 [12800/47000 (27%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 9 [15360/47000 (33%)]\tLoss: 1.865481\n",
      "Train Unlabeled Epoch: 9 [17920/47000 (38%)]\tLoss: 1.865469\n",
      "Train Unlabeled Epoch: 9 [20480/47000 (43%)]\tLoss: 1.865600\n",
      "Train Unlabeled Epoch: 9 [23040/47000 (49%)]\tLoss: 1.865507\n",
      "Train Unlabeled Epoch: 9 [25600/47000 (54%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 9 [28160/47000 (60%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 9 [30720/47000 (65%)]\tLoss: 1.865455\n",
      "Train Unlabeled Epoch: 9 [33280/47000 (71%)]\tLoss: 1.865622\n",
      "Train Unlabeled Epoch: 9 [35840/47000 (76%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 9 [38400/47000 (82%)]\tLoss: 1.865482\n",
      "Train Unlabeled Epoch: 9 [40960/47000 (87%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 9 [43520/47000 (92%)]\tLoss: 1.865516\n",
      "Train Unlabeled Epoch: 9 [46080/47000 (98%)]\tLoss: 1.865452\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 10 [0/3000 (0%)]\tLoss: 2.318566\n",
      "Train Labeled Epoch: 10 [320/3000 (11%)]\tLoss: 2.318407\n",
      "Train Labeled Epoch: 10 [640/3000 (21%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 10 [960/3000 (32%)]\tLoss: 2.318558\n",
      "Train Labeled Epoch: 10 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 10 [1600/3000 (53%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 10 [1920/3000 (64%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 10 [2240/3000 (74%)]\tLoss: 2.302939\n",
      "Train Labeled Epoch: 10 [2560/3000 (85%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 10 [2880/3000 (96%)]\tLoss: 2.318565\n",
      "Train Unlabeled Epoch: 10 [0/47000 (0%)]\tLoss: 1.865454\n",
      "Train Unlabeled Epoch: 10 [2560/47000 (5%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 10 [5120/47000 (11%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 10 [7680/47000 (16%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 10 [10240/47000 (22%)]\tLoss: 1.865501\n",
      "Train Unlabeled Epoch: 10 [12800/47000 (27%)]\tLoss: 1.865492\n",
      "Train Unlabeled Epoch: 10 [15360/47000 (33%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 10 [17920/47000 (38%)]\tLoss: 1.865460\n",
      "Train Unlabeled Epoch: 10 [20480/47000 (43%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 10 [23040/47000 (49%)]\tLoss: 1.865456\n",
      "Train Unlabeled Epoch: 10 [25600/47000 (54%)]\tLoss: 1.865575\n",
      "Train Unlabeled Epoch: 10 [28160/47000 (60%)]\tLoss: 1.865470\n",
      "Train Unlabeled Epoch: 10 [30720/47000 (65%)]\tLoss: 1.865468\n",
      "Train Unlabeled Epoch: 10 [33280/47000 (71%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 10 [35840/47000 (76%)]\tLoss: 1.865489\n",
      "Train Unlabeled Epoch: 10 [38400/47000 (82%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 10 [40960/47000 (87%)]\tLoss: 1.865916\n",
      "Train Unlabeled Epoch: 10 [43520/47000 (92%)]\tLoss: 1.866270\n",
      "Train Unlabeled Epoch: 10 [46080/47000 (98%)]\tLoss: 1.865451\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 11 [0/3000 (0%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 11 [320/3000 (11%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 11 [640/3000 (21%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 11 [960/3000 (32%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 11 [1280/3000 (43%)]\tLoss: 2.271690\n",
      "Train Labeled Epoch: 11 [1600/3000 (53%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 11 [1920/3000 (64%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 11 [2240/3000 (74%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 11 [2560/3000 (85%)]\tLoss: 2.365440\n",
      "Train Labeled Epoch: 11 [2880/3000 (96%)]\tLoss: 2.256065\n",
      "Train Unlabeled Epoch: 11 [0/47000 (0%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 11 [2560/47000 (5%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 11 [5120/47000 (11%)]\tLoss: 1.865469\n",
      "Train Unlabeled Epoch: 11 [7680/47000 (16%)]\tLoss: 1.865457\n",
      "Train Unlabeled Epoch: 11 [10240/47000 (22%)]\tLoss: 1.865482\n",
      "Train Unlabeled Epoch: 11 [12800/47000 (27%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 11 [15360/47000 (33%)]\tLoss: 1.865508\n",
      "Train Unlabeled Epoch: 11 [17920/47000 (38%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 11 [20480/47000 (43%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 11 [23040/47000 (49%)]\tLoss: 1.865486\n",
      "Train Unlabeled Epoch: 11 [25600/47000 (54%)]\tLoss: 1.865463\n",
      "Train Unlabeled Epoch: 11 [28160/47000 (60%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 11 [30720/47000 (65%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 11 [33280/47000 (71%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 11 [35840/47000 (76%)]\tLoss: 1.865473\n",
      "Train Unlabeled Epoch: 11 [38400/47000 (82%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 11 [40960/47000 (87%)]\tLoss: 1.865461\n",
      "Train Unlabeled Epoch: 11 [43520/47000 (92%)]\tLoss: 1.865545\n",
      "Train Unlabeled Epoch: 11 [46080/47000 (98%)]\tLoss: 1.865470\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 12 [0/3000 (0%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 12 [320/3000 (11%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 12 [640/3000 (21%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 12 [960/3000 (32%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 12 [1280/3000 (43%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 12 [1600/3000 (53%)]\tLoss: 2.349658\n",
      "Train Labeled Epoch: 12 [1920/3000 (64%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 12 [2240/3000 (74%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 12 [2560/3000 (85%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 12 [2880/3000 (96%)]\tLoss: 2.334190\n",
      "Train Unlabeled Epoch: 12 [0/47000 (0%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 12 [2560/47000 (5%)]\tLoss: 1.865529\n",
      "Train Unlabeled Epoch: 12 [5120/47000 (11%)]\tLoss: 1.865589\n",
      "Train Unlabeled Epoch: 12 [7680/47000 (16%)]\tLoss: 1.865483\n",
      "Train Unlabeled Epoch: 12 [10240/47000 (22%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 12 [12800/47000 (27%)]\tLoss: 1.866494\n",
      "Train Unlabeled Epoch: 12 [15360/47000 (33%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 12 [17920/47000 (38%)]\tLoss: 1.865520\n",
      "Train Unlabeled Epoch: 12 [20480/47000 (43%)]\tLoss: 1.865496\n",
      "Train Unlabeled Epoch: 12 [23040/47000 (49%)]\tLoss: 1.865462\n",
      "Train Unlabeled Epoch: 12 [25600/47000 (54%)]\tLoss: 1.865536\n",
      "Train Unlabeled Epoch: 12 [28160/47000 (60%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 12 [30720/47000 (65%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 12 [33280/47000 (71%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 12 [35840/47000 (76%)]\tLoss: 1.865573\n",
      "Train Unlabeled Epoch: 12 [38400/47000 (82%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 12 [40960/47000 (87%)]\tLoss: 1.865593\n",
      "Train Unlabeled Epoch: 12 [43520/47000 (92%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 12 [46080/47000 (98%)]\tLoss: 1.865522\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 13 [0/3000 (0%)]\tLoss: 2.349818\n",
      "Train Labeled Epoch: 13 [320/3000 (11%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 13 [640/3000 (21%)]\tLoss: 2.287585\n",
      "Train Labeled Epoch: 13 [960/3000 (32%)]\tLoss: 2.256065\n",
      "Train Labeled Epoch: 13 [1280/3000 (43%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 13 [1600/3000 (53%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 13 [1920/3000 (64%)]\tLoss: 2.349814\n",
      "Train Labeled Epoch: 13 [2240/3000 (74%)]\tLoss: 2.334187\n",
      "Train Labeled Epoch: 13 [2560/3000 (85%)]\tLoss: 2.271690\n",
      "Train Labeled Epoch: 13 [2880/3000 (96%)]\tLoss: 2.303283\n",
      "Train Unlabeled Epoch: 13 [0/47000 (0%)]\tLoss: 1.865502\n",
      "Train Unlabeled Epoch: 13 [2560/47000 (5%)]\tLoss: 1.865452\n",
      "Train Unlabeled Epoch: 13 [5120/47000 (11%)]\tLoss: 1.865645\n",
      "Train Unlabeled Epoch: 13 [7680/47000 (16%)]\tLoss: 1.865466\n",
      "Train Unlabeled Epoch: 13 [10240/47000 (22%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 13 [12800/47000 (27%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 13 [15360/47000 (33%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 13 [17920/47000 (38%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 13 [20480/47000 (43%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 13 [23040/47000 (49%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 13 [25600/47000 (54%)]\tLoss: 1.865461\n",
      "Train Unlabeled Epoch: 13 [28160/47000 (60%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 13 [30720/47000 (65%)]\tLoss: 1.865602\n",
      "Train Unlabeled Epoch: 13 [33280/47000 (71%)]\tLoss: 1.865473\n",
      "Train Unlabeled Epoch: 13 [35840/47000 (76%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 13 [38400/47000 (82%)]\tLoss: 1.865472\n",
      "Train Unlabeled Epoch: 13 [40960/47000 (87%)]\tLoss: 1.865519\n",
      "Train Unlabeled Epoch: 13 [43520/47000 (92%)]\tLoss: 1.865456\n",
      "Train Unlabeled Epoch: 13 [46080/47000 (98%)]\tLoss: 1.867028\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 14 [0/3000 (0%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 14 [320/3000 (11%)]\tLoss: 2.256062\n",
      "Train Labeled Epoch: 14 [640/3000 (21%)]\tLoss: 2.318563\n",
      "Train Labeled Epoch: 14 [960/3000 (32%)]\tLoss: 2.318506\n",
      "Train Labeled Epoch: 14 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 14 [1600/3000 (53%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 14 [1920/3000 (64%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 14 [2240/3000 (74%)]\tLoss: 2.334148\n",
      "Train Labeled Epoch: 14 [2560/3000 (85%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 14 [2880/3000 (96%)]\tLoss: 2.302935\n",
      "Train Unlabeled Epoch: 14 [0/47000 (0%)]\tLoss: 1.865462\n",
      "Train Unlabeled Epoch: 14 [2560/47000 (5%)]\tLoss: 1.865623\n",
      "Train Unlabeled Epoch: 14 [5120/47000 (11%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 14 [7680/47000 (16%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 14 [10240/47000 (22%)]\tLoss: 1.865531\n",
      "Train Unlabeled Epoch: 14 [12800/47000 (27%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 14 [15360/47000 (33%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 14 [17920/47000 (38%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 14 [20480/47000 (43%)]\tLoss: 1.865524\n",
      "Train Unlabeled Epoch: 14 [23040/47000 (49%)]\tLoss: 1.865461\n",
      "Train Unlabeled Epoch: 14 [25600/47000 (54%)]\tLoss: 1.865456\n",
      "Train Unlabeled Epoch: 14 [28160/47000 (60%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 14 [30720/47000 (65%)]\tLoss: 1.865645\n",
      "Train Unlabeled Epoch: 14 [33280/47000 (71%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 14 [35840/47000 (76%)]\tLoss: 1.865450\n",
      "Train Unlabeled Epoch: 14 [38400/47000 (82%)]\tLoss: 1.865519\n",
      "Train Unlabeled Epoch: 14 [40960/47000 (87%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 14 [43520/47000 (92%)]\tLoss: 1.865470\n",
      "Train Unlabeled Epoch: 14 [46080/47000 (98%)]\tLoss: 1.865615\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 15 [0/3000 (0%)]\tLoss: 2.318564\n",
      "Train Labeled Epoch: 15 [320/3000 (11%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 15 [640/3000 (21%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 15 [960/3000 (32%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 15 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 15 [1600/3000 (53%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 15 [1920/3000 (64%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 15 [2240/3000 (74%)]\tLoss: 2.288338\n",
      "Train Labeled Epoch: 15 [2560/3000 (85%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 15 [2880/3000 (96%)]\tLoss: 2.318669\n",
      "Train Unlabeled Epoch: 15 [0/47000 (0%)]\tLoss: 1.865538\n",
      "Train Unlabeled Epoch: 15 [2560/47000 (5%)]\tLoss: 1.865588\n",
      "Train Unlabeled Epoch: 15 [5120/47000 (11%)]\tLoss: 1.865452\n",
      "Train Unlabeled Epoch: 15 [7680/47000 (16%)]\tLoss: 1.865709\n",
      "Train Unlabeled Epoch: 15 [10240/47000 (22%)]\tLoss: 1.865482\n",
      "Train Unlabeled Epoch: 15 [12800/47000 (27%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 15 [15360/47000 (33%)]\tLoss: 1.865446\n",
      "Train Unlabeled Epoch: 15 [17920/47000 (38%)]\tLoss: 1.866129\n",
      "Train Unlabeled Epoch: 15 [20480/47000 (43%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 15 [23040/47000 (49%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 15 [25600/47000 (54%)]\tLoss: 1.865562\n",
      "Train Unlabeled Epoch: 15 [28160/47000 (60%)]\tLoss: 1.865494\n",
      "Train Unlabeled Epoch: 15 [30720/47000 (65%)]\tLoss: 1.865480\n",
      "Train Unlabeled Epoch: 15 [33280/47000 (71%)]\tLoss: 1.865770\n",
      "Train Unlabeled Epoch: 15 [35840/47000 (76%)]\tLoss: 1.865452\n",
      "Train Unlabeled Epoch: 15 [38400/47000 (82%)]\tLoss: 1.865466\n",
      "Train Unlabeled Epoch: 15 [40960/47000 (87%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 15 [43520/47000 (92%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 15 [46080/47000 (98%)]\tLoss: 1.865572\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 16 [0/3000 (0%)]\tLoss: 2.318547\n",
      "Train Labeled Epoch: 16 [320/3000 (11%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 16 [640/3000 (21%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 16 [960/3000 (32%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 16 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 16 [1600/3000 (53%)]\tLoss: 2.318564\n",
      "Train Labeled Epoch: 16 [1920/3000 (64%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 16 [2240/3000 (74%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 16 [2560/3000 (85%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 16 [2880/3000 (96%)]\tLoss: 2.318565\n",
      "Train Unlabeled Epoch: 16 [0/47000 (0%)]\tLoss: 1.865478\n",
      "Train Unlabeled Epoch: 16 [2560/47000 (5%)]\tLoss: 1.865478\n",
      "Train Unlabeled Epoch: 16 [5120/47000 (11%)]\tLoss: 1.865477\n",
      "Train Unlabeled Epoch: 16 [7680/47000 (16%)]\tLoss: 1.865469\n",
      "Train Unlabeled Epoch: 16 [10240/47000 (22%)]\tLoss: 1.865456\n",
      "Train Unlabeled Epoch: 16 [12800/47000 (27%)]\tLoss: 1.865481\n",
      "Train Unlabeled Epoch: 16 [15360/47000 (33%)]\tLoss: 1.865523\n",
      "Train Unlabeled Epoch: 16 [17920/47000 (38%)]\tLoss: 1.865588\n",
      "Train Unlabeled Epoch: 16 [20480/47000 (43%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 16 [23040/47000 (49%)]\tLoss: 1.865469\n",
      "Train Unlabeled Epoch: 16 [25600/47000 (54%)]\tLoss: 1.865451\n",
      "Train Unlabeled Epoch: 16 [28160/47000 (60%)]\tLoss: 1.865489\n",
      "Train Unlabeled Epoch: 16 [30720/47000 (65%)]\tLoss: 1.865453\n",
      "Train Unlabeled Epoch: 16 [33280/47000 (71%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 16 [35840/47000 (76%)]\tLoss: 1.865449\n",
      "Train Unlabeled Epoch: 16 [38400/47000 (82%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 16 [40960/47000 (87%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 16 [43520/47000 (92%)]\tLoss: 1.865465\n",
      "Train Unlabeled Epoch: 16 [46080/47000 (98%)]\tLoss: 1.865710\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 17 [0/3000 (0%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 17 [320/3000 (11%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 17 [640/3000 (21%)]\tLoss: 2.349811\n",
      "Train Labeled Epoch: 17 [960/3000 (32%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 17 [1280/3000 (43%)]\tLoss: 2.334188\n",
      "Train Labeled Epoch: 17 [1600/3000 (53%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 17 [1920/3000 (64%)]\tLoss: 2.365440\n",
      "Train Labeled Epoch: 17 [2240/3000 (74%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 17 [2560/3000 (85%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 17 [2880/3000 (96%)]\tLoss: 2.334190\n",
      "Train Unlabeled Epoch: 17 [0/47000 (0%)]\tLoss: 1.865458\n",
      "Train Unlabeled Epoch: 17 [2560/47000 (5%)]\tLoss: 1.865578\n",
      "Train Unlabeled Epoch: 17 [5120/47000 (11%)]\tLoss: 1.865520\n",
      "Train Unlabeled Epoch: 17 [7680/47000 (16%)]\tLoss: 1.865456\n",
      "Train Unlabeled Epoch: 17 [10240/47000 (22%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 17 [12800/47000 (27%)]\tLoss: 1.865461\n",
      "Train Unlabeled Epoch: 17 [15360/47000 (33%)]\tLoss: 1.865526\n",
      "Train Unlabeled Epoch: 17 [17920/47000 (38%)]\tLoss: 1.865936\n",
      "Train Unlabeled Epoch: 17 [20480/47000 (43%)]\tLoss: 1.865476\n",
      "Train Unlabeled Epoch: 17 [23040/47000 (49%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 17 [25600/47000 (54%)]\tLoss: 1.865719\n",
      "Train Unlabeled Epoch: 17 [28160/47000 (60%)]\tLoss: 1.865460\n",
      "Train Unlabeled Epoch: 17 [30720/47000 (65%)]\tLoss: 1.865517\n",
      "Train Unlabeled Epoch: 17 [33280/47000 (71%)]\tLoss: 1.866461\n",
      "Train Unlabeled Epoch: 17 [35840/47000 (76%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 17 [38400/47000 (82%)]\tLoss: 1.865476\n",
      "Train Unlabeled Epoch: 17 [40960/47000 (87%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 17 [43520/47000 (92%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 17 [46080/47000 (98%)]\tLoss: 1.865445\n",
      "\n",
      "Test set: Average loss: 2.3154, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 18 [0/3000 (0%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 18 [320/3000 (11%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 18 [640/3000 (21%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 18 [960/3000 (32%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 18 [1280/3000 (43%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 18 [1600/3000 (53%)]\tLoss: 2.349815\n",
      "Train Labeled Epoch: 18 [1920/3000 (64%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 18 [2240/3000 (74%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 18 [2560/3000 (85%)]\tLoss: 2.287315\n",
      "Train Labeled Epoch: 18 [2880/3000 (96%)]\tLoss: 2.318565\n",
      "Train Unlabeled Epoch: 18 [0/47000 (0%)]\tLoss: 1.865442\n",
      "Train Unlabeled Epoch: 18 [2560/47000 (5%)]\tLoss: 1.865498\n",
      "Train Unlabeled Epoch: 18 [5120/47000 (11%)]\tLoss: 1.865575\n",
      "Train Unlabeled Epoch: 18 [7680/47000 (16%)]\tLoss: 1.865594\n",
      "Train Unlabeled Epoch: 18 [10240/47000 (22%)]\tLoss: 1.865486\n",
      "Train Unlabeled Epoch: 18 [12800/47000 (27%)]\tLoss: 1.865464\n",
      "Train Unlabeled Epoch: 18 [15360/47000 (33%)]\tLoss: 1.865499\n",
      "Train Unlabeled Epoch: 18 [17920/47000 (38%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 18 [20480/47000 (43%)]\tLoss: 1.865454\n",
      "Train Unlabeled Epoch: 18 [23040/47000 (49%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 18 [25600/47000 (54%)]\tLoss: 1.865445\n",
      "Train Unlabeled Epoch: 18 [28160/47000 (60%)]\tLoss: 1.865513\n",
      "Train Unlabeled Epoch: 18 [30720/47000 (65%)]\tLoss: 1.865455\n",
      "Train Unlabeled Epoch: 18 [33280/47000 (71%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 18 [35840/47000 (76%)]\tLoss: 1.865450\n",
      "Train Unlabeled Epoch: 18 [38400/47000 (82%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 18 [40960/47000 (87%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 18 [43520/47000 (92%)]\tLoss: 1.865448\n",
      "Train Unlabeled Epoch: 18 [46080/47000 (98%)]\tLoss: 1.865475\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Labeled Epoch: 19 [0/3000 (0%)]\tLoss: 2.287314\n",
      "Train Labeled Epoch: 19 [320/3000 (11%)]\tLoss: 2.334189\n",
      "Train Labeled Epoch: 19 [640/3000 (21%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 19 [960/3000 (32%)]\tLoss: 2.302940\n",
      "Train Labeled Epoch: 19 [1280/3000 (43%)]\tLoss: 2.334190\n",
      "Train Labeled Epoch: 19 [1600/3000 (53%)]\tLoss: 2.318565\n",
      "Train Labeled Epoch: 19 [1920/3000 (64%)]\tLoss: 2.318542\n",
      "Train Labeled Epoch: 19 [2240/3000 (74%)]\tLoss: 2.271690\n",
      "Train Labeled Epoch: 19 [2560/3000 (85%)]\tLoss: 2.365433\n",
      "Train Labeled Epoch: 19 [2880/3000 (96%)]\tLoss: 2.318565\n",
      "Train Unlabeled Epoch: 19 [0/47000 (0%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 19 [2560/47000 (5%)]\tLoss: 1.865628\n",
      "Train Unlabeled Epoch: 19 [5120/47000 (11%)]\tLoss: 1.865467\n",
      "Train Unlabeled Epoch: 19 [7680/47000 (16%)]\tLoss: 1.865450\n",
      "Train Unlabeled Epoch: 19 [10240/47000 (22%)]\tLoss: 1.865450\n",
      "Train Unlabeled Epoch: 19 [12800/47000 (27%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 19 [15360/47000 (33%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 19 [17920/47000 (38%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 19 [20480/47000 (43%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 19 [23040/47000 (49%)]\tLoss: 1.865447\n",
      "Train Unlabeled Epoch: 19 [25600/47000 (54%)]\tLoss: 1.865443\n",
      "Train Unlabeled Epoch: 19 [28160/47000 (60%)]\tLoss: 1.865460\n",
      "Train Unlabeled Epoch: 19 [30720/47000 (65%)]\tLoss: 1.865510\n",
      "Train Unlabeled Epoch: 19 [33280/47000 (71%)]\tLoss: 1.865619\n",
      "Train Unlabeled Epoch: 19 [35840/47000 (76%)]\tLoss: 1.865444\n",
      "Train Unlabeled Epoch: 19 [38400/47000 (82%)]\tLoss: 1.865464\n",
      "Train Unlabeled Epoch: 19 [40960/47000 (87%)]\tLoss: 1.865477\n",
      "Train Unlabeled Epoch: 19 [43520/47000 (92%)]\tLoss: 1.865457\n",
      "Train Unlabeled Epoch: 19 [46080/47000 (98%)]\tLoss: 1.865535\n",
      "\n",
      "Test set: Average loss: 2.3155, Accuracy: 1000/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, 20):\n",
    "    train(epoch)\n",
    "    validate(epoch, valid_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = pickle.load(open(\"../data/kaggle/test.p\", \"rb\"))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "#         test_loss += F.cross_entropy(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "#         correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "#     test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(valid_loader.dataset),\n",
    "#         100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test(1, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "label_predict = np.array([])\n",
    "model.eval()\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    temp = output.data.max(1)[1].numpy().reshape(-1)\n",
    "    \n",
    "    label_predict = np.concatenate((label_predict, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_predict\n",
    "\n",
    "predict_label = pd.DataFrame(label_predict, columns=['label'], dtype=int)\n",
    "predict_label.reset_index(inplace=True)\n",
    "predict_label.rename(columns={'index': 'ID'}, inplace=True)\n",
    "\n",
    "predict_label.head()\n",
    "\n",
    "predict_label.to_csv('../data/kaggle/sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
