{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle \n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(trainset_new, batch_size=64, shuffle=True)\n",
    "# valid_loader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "trainset_imoprt = pickle.load(open(\"../data/kaggle/train_labeled.p\", \"rb\"))\n",
    "validset_import = pickle.load(open(\"../data/kaggle/validation.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset_imoprt, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validset_import, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if False:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        \n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d(0.3)\n",
    "        self.fc1 = nn.Linear(320, 160)\n",
    "        self.fc2 = nn.Linear(160, 80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.data.size())\n",
    "        x = x.view(-1, 1, 28,28)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return F.log_softmax(x)\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruction_function = nn.BCELoss()\n",
    "reconstruction_function.size_average = False\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CPU only training\n",
    "def generate_train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "    \n",
    "def generate_test(epoch, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for data, _ in test_loader:\n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: -1851.565186\n",
      "====> Epoch: 1 Average loss: -7463.6835\n",
      "====> Test set loss: -9509.6973\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: -9677.851562\n",
      "====> Epoch: 2 Average loss: -9857.4584\n",
      "====> Test set loss: -9889.9778\n",
      "Train Epoch: 3 [0/3000 (0%)]\tLoss: -10056.569336\n",
      "====> Epoch: 3 Average loss: -10054.9688\n",
      "====> Test set loss: -9978.5220\n",
      "Train Epoch: 4 [0/3000 (0%)]\tLoss: -10145.400391\n",
      "====> Epoch: 4 Average loss: -10132.9395\n",
      "====> Test set loss: -10031.9572\n",
      "Train Epoch: 5 [0/3000 (0%)]\tLoss: -10300.203125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-8f47400d98a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Generative phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgenerate_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgenerate_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-8b45e33bc224>\u001b[0m in \u001b[0;36mgenerate_train\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
      "\u001b[0;32m/Users/sivagurukannan/anaconda/envs/tensorflow/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Generative phase\n",
    "for epoch in range(1, 20):\n",
    "    generate_train(epoch)\n",
    "    generate_test(epoch, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CPU only training\n",
    "def train(epoch):\n",
    "    classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        gen_data, mu, logvar = model(data)\n",
    "        #Check reconstruction loss \n",
    "        recon_loss = reconstruction_function(gen_data, data)\n",
    "        print(\"Reconstruction loss is\", recon_loss)\n",
    "        print(\"Type of generated data\", type(gen_data))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(gen_data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        gen_data, mu, logvar = model(data)\n",
    "        output = classifier(gen_data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5178\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 2.299191\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6905\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -2.1476\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.9056\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8477\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.9292\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6549\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6847\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7019\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7284\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7118\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 2.286551\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5943\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6363\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7810\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8545\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7127\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7505\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7982\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6603\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3185\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 1 [1280/3000 (43%)]\tLoss: 2.299393\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6320\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.9045\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3162\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3935\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.0717\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3920\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7530\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5373\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "-94206.6172\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 1 [1920/3000 (64%)]\tLoss: 2.296539\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2300\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7360\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4979\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2892\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4929\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5754\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7574\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6003\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 1 [2560/3000 (85%)]\tLoss: 2.285735\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5269\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5021\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5358\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6477\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6083\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8028\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "Test set: Average loss: 2.2939, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4947\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 2.291644\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6222\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5508\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8440\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4819\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5570\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6517\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5553\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6820\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2158\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5619\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 2 [640/3000 (21%)]\tLoss: 2.293734\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4997\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2443\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4211\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3728\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4760\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4031\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.1540\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2327\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2842\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Train Epoch: 2 [1280/3000 (43%)]\tLoss: 2.292473\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.1890\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3280\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4028\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.1465\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4470\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "-95438.1719\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n",
      "Reconstruction loss is Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2799\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Type of generated data <class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-9e68f7b2c7c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Classification phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-afa56b4b1fcc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sivagurukannan/anaconda/envs/tensorflow/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sivagurukannan/anaconda/envs/tensorflow/lib/python3.5/site-packages/torch/nn/_functions/linear.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mgrad_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mgrad_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Classification phase\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test(epoch, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = pickle.load(open(\"../data/kaggle/test.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1253, Accuracy: 9586/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_predict = np.array([])\n",
    "model.eval()\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    temp = output.data.max(1)[1].numpy().reshape(-1)\n",
    "    label_predict = np.concatenate((label_predict, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.,  2.,  1., ...,  4.,  5.,  6.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_label = pd.DataFrame(label_predict, columns=['label'], dtype=int)\n",
    "predict_label.reset_index(inplace=True)\n",
    "predict_label.rename(columns={'index': 'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label\n",
       "0   0      7\n",
       "1   1      2\n",
       "2   2      1\n",
       "3   3      0\n",
       "4   4      4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_label.to_csv('../data/kaggle/sample_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
